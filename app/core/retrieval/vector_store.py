from langchain_qdrant import Qdrant
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from qdrant_client import QdrantClient
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

from app.config import settings
from app.logs.logger import setup_logger

logger = setup_logger('vector_store')

@dataclass
class CollectionInfo:
    """ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    user_id: str
    book_key: str = "default"


class VectorStoreError(Exception):
    """VectorStore ê´€ë ¨ ì˜ˆì™¸"""
    pass


class VectorStore:
    """ë²¡í„° DB ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, embeddings: OpenAIEmbeddings):
        """VectorStore ì´ˆê¸°í™”"""
        self.embeddings = embeddings
        self._client: Optional[QdrantClient] = None
        self._collection_cache: Dict[str, bool] = {}  # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ ìºì‹œ
    
    def _get_client(self) -> QdrantClient:
        """ê³µí†µ Qdrant í´ë¼ì´ì–¸íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (HTTP ëª¨ë“œë¡œ ìˆ˜ì •)"""
        if self._client is None:
            try:
                self._client = QdrantClient(
                    url=settings.QDRANT_URL,
                    api_key=settings.QDRANT_API_KEY,
                    timeout=settings.QDRANT_TIMEOUT,
                    prefer_grpc=False  # HTTP ëª¨ë“œ ì‚¬ìš©
                )
                logger.info("Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (HTTP ëª¨ë“œ)")
            except Exception as e:
                logger.error(f"Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return self._client
    
    def get_user_collection_name(self, user_id: str) -> str:
        """ì‚¬ìš©ìë³„ ì»¬ë ‰ì…˜ ì´ë¦„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        return f"{user_id}{settings.USER_COLLECTION_SUFFIX}"
    
    def get_user_collection(self, user_id: str) -> Optional[str]:
        """ì‚¬ìš©ìë³„ ì»¬ë ‰ì…˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (ìµœì í™”ëœ ë²„ì „)"""
        try:
            # ì‚¬ìš©ìë³„ ì»¬ë ‰ì…˜ ì´ë¦„ ì§ì ‘ ìƒì„±
            expected_collection_name = self.get_user_collection_name(user_id)
            
            # í•´ë‹¹ ì»¬ë ‰ì…˜ë§Œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if self._collection_exists(expected_collection_name):
                return expected_collection_name
            else:
                logger.info(f"ğŸ“ ì‚¬ìš©ì {user_id}ì˜ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤ (ìƒˆë¡œ ìƒì„± ì˜ˆì •): {expected_collection_name}")
                return None
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì {user_id} ì»¬ë ‰ì…˜ ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            raise VectorStoreError(f"ì»¬ë ‰ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    def _collection_exists(self, collection_name: str) -> bool:
        """ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. (ìºì‹œ ë¬´íš¨í™” ê°œì„ )"""
        try:
            client = self._get_client()
            client.get_collection(collection_name)
            self._collection_cache[collection_name] = True
            return True
        except Exception as e:
            logger.info(f"ì»¬ë ‰ì…˜ {collection_name}ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„± ì˜ˆì •")
            self._collection_cache[collection_name] = False
            return False
    
    def _extract_collection_info(self, collection_name: str) -> CollectionInfo:
        """ì»¬ë ‰ì…˜ ì´ë¦„ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if not collection_name.endswith(settings.USER_COLLECTION_SUFFIX):
            raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì»¬ë ‰ì…˜ ì´ë¦„: {collection_name}")
        
        # suffix ì œê±°
        name_without_suffix = collection_name[:-len(settings.USER_COLLECTION_SUFFIX)]
        
        # user_id_bookKey í˜•ì‹ì¸ì§€ í™•ì¸
        if "_" in name_without_suffix:
            parts = name_without_suffix.split("_", 1)
            user_id = parts[0]
            book_key = parts[1]
        else:
            # ê¸°ì¡´ í˜•ì‹ (bookKey ì—†ìŒ)
            user_id = name_without_suffix
            book_key = "default"
        
        return CollectionInfo(name=collection_name, user_id=user_id, book_key=book_key)
    
    def _add_book_id_to_chunks(self, chunks: List[Document], book_id: int) -> None:
        """ì²­í¬ì— book_id ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        for chunk in chunks:
            if hasattr(chunk, 'metadata') and chunk.metadata:
                chunk.metadata['book_id'] = book_id
                # upload_timestampê°€ ì´ë¯¸ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
                if 'upload_timestamp' not in chunk.metadata:
                    from datetime import datetime
                    import time
                    chunk.metadata['upload_timestamp'] = datetime.now().isoformat()
            
    def create_vector_db(self, chunks: List[Document], user_id: str, book_id: int) -> bool:
        """ì²­í¬ë¥¼ ì‚¬ìš©ìë³„ ë²¡í„° DBì— ì €ì¥í•©ë‹ˆë‹¤. (ì‚¬ìš©ì ë‹¨ìœ„ ì»¬ë ‰ì…˜)"""
        try:
            collection_name = self.get_user_collection_name(user_id)
            logger.info(f"ğŸ”„ ë²¡í„° DB ìƒì„± ì‹œì‘")
            logger.info(f"   ğŸ‘¤ ì‚¬ìš©ì: {user_id}")
            logger.info(f"   ğŸ“š ë„ì„œ ID: {book_id}")
            logger.info(f"   ğŸ—‚ï¸  ì»¬ë ‰ì…˜: {collection_name}")
            logger.info(f"   ğŸ“Š ì €ì¥í•  ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
            
            # book_id ì •ë³´ë¥¼ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
            self._add_book_id_to_chunks(chunks, book_id)
            
            if self._collection_exists(collection_name):
                logger.info(f"   ğŸ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ {collection_name} ë°œê²¬ - ì²­í¬ ì¶”ê°€ ëª¨ë“œ")
                return self._add_to_existing_collection(collection_name, chunks, user_id)
            else:
                logger.info(f"   ğŸ†• ìƒˆ ì»¬ë ‰ì…˜ {collection_name} ìƒì„± ëª¨ë“œ")
                return self._create_new_collection(collection_name, chunks)
                
        except Exception as e:
            logger.error(f"ë²¡í„° DB ìƒì„± ì‹¤íŒ¨ - ì‚¬ìš©ì: {user_id}, ì˜¤ë¥˜: {e}")
            raise VectorStoreError(f"ë²¡í„° DB ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _add_to_existing_collection(self, collection_name: str, chunks: List[Document], user_id: str) -> bool:
        """ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ì²­í¬ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        logger.info(f"   ğŸ“ ê¸°ì¡´ ì»¬ë ‰ì…˜ {collection_name}ì— ì²­í¬ ì¶”ê°€ ì‹œì‘")
        
        try:
            logger.info(f"   ğŸ”„ {len(chunks)}ê°œ ì²­í¬ë¥¼ ë²¡í„° DBì— ì €ì¥ ì¤‘...")
            
            # í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¥
            client = self._get_client()
            
            # ê¸°ì¡´ í¬ì¸íŠ¸ ìˆ˜ í™•ì¸
            existing_points = client.scroll(
                collection_name=collection_name,
                limit=10000,  # ì¶©ë¶„íˆ í° ìˆ˜ë¡œ ëª¨ë“  í¬ì¸íŠ¸ ì¡°íšŒ
                with_payload=False
            )[0]
            start_id = len(existing_points)
            
            # ê° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¥
            for i, chunk in enumerate(chunks):
                # ì„ë² ë”© ìƒì„±
                embedding = self.embeddings.embed_query(chunk.page_content)
                
                # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                payload = {
                    "page_content": chunk.page_content,
                    "metadata": chunk.metadata
                }
                
                # í¬ì¸íŠ¸ ì¶”ê°€ (IDë¥¼ ì •ìˆ˜ë¡œ ìƒì„±)
                client.upsert(
                    collection_name=collection_name,
                    points=[{
                        "id": start_id + i,  # ì •ìˆ˜ ID ì‚¬ìš©
                        "vector": embedding,
                        "payload": payload
                    }]
                )
            
            logger.info(f"   âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ {collection_name}ì— {len(chunks)}ê°œ ì²­í¬ ì¶”ê°€ ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"   âŒ ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ì²­í¬ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def _create_new_collection(self, collection_name: str, chunks: List[Document]) -> bool:
        """ìƒˆ ì»¬ë ‰ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        logger.info(f"   ğŸ†• ìƒˆ ì»¬ë ‰ì…˜ {collection_name} ìƒì„± ì‹œì‘")
        
        try:
            logger.info(f"   ğŸ”„ {len(chunks)}ê°œ ì²­í¬ë¡œ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì¤‘...")
            
            # í´ë¼ì´ì–¸íŠ¸ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¥
            client = self._get_client()
            
            # ì»¬ë ‰ì…˜ ìƒì„± (ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë¬´ì‹œ)
            from qdrant_client.models import Distance, VectorParams
            try:
                client.create_collection(
                    collection_name=collection_name,
                    vectors_config=VectorParams(
                        size=1536,  # OpenAI embedding í¬ê¸°
                        distance=Distance.COSINE
                    )
                )
            except Exception as e:
                # ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë¬´ì‹œ
                logger.info(f"   ğŸ“ ì»¬ë ‰ì…˜ {collection_name}ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            
            # ê° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ë©”íƒ€ë°ì´í„° ë³´ì¥
            for i, chunk in enumerate(chunks):
                # ì„ë² ë”© ìƒì„±
                embedding = self.embeddings.embed_query(chunk.page_content)
                
                # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
                payload = {
                    "page_content": chunk.page_content,
                    "metadata": chunk.metadata
                }
                
                # í¬ì¸íŠ¸ ì¶”ê°€ (IDë¥¼ ì •ìˆ˜ë¡œ ìƒì„±)
                client.upsert(
                    collection_name=collection_name,
                    points=[{
                        "id": i,  # ì •ìˆ˜ ID ì‚¬ìš©
                        "vector": embedding,
                        "payload": payload
                    }]
                )
            
            logger.info(f"   âœ… ìƒˆ ì»¬ë ‰ì…˜ {collection_name} ìƒì„± ì™„ë£Œ - {len(chunks)}ê°œ ì²­í¬")
            return True
        except Exception as e:
            logger.error(f"   âŒ ìƒˆ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def get_vector_db_for_user(self, user_id: str, collection_name: str) -> Optional[Qdrant]:
        """ì‚¬ìš©ìë³„ ë²¡í„° DBë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ì‚¬ìš©ì ë‹¨ìœ„ ì»¬ë ‰ì…˜)"""
        try:
            if not collection_name:
                collection_name = self.get_user_collection_name(user_id)
            
            client = self._get_client()
            vector_db = Qdrant(
                client=client,
                collection_name=collection_name,
                embeddings=self.embeddings
            )
            
            return vector_db
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì {user_id} ë²¡í„° DB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return None

    def get_user_document_detail(self, user_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ì‚¬ìš©ìì˜ ë¬¸ì„œ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. (ì‚¬ìš©ì ë‹¨ìœ„ ì»¬ë ‰ì…˜)"""
        try:
            client = self._get_client()
            
            # ì‚¬ìš©ìì˜ ì»¬ë ‰ì…˜ ì¡°íšŒ
            collection_name = self.get_user_collection(user_id)
            
            if not collection_name:
                return None
            
            user_books = {}
            
            try:
                # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  í¬ì¸íŠ¸ ì¡°íšŒ
                # ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ ì •ë ¬ ì˜µì…˜ ì¶”ê°€
                points = client.scroll(
                    collection_name=collection_name,
                    limit=10000,  # ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì§€ì›ì„ ìœ„í•´ ì¦ê°€
                    with_payload=True,
                    with_vectors=False
                )[0]
                
                logger.info(f"ğŸ” ì‚¬ìš©ì {user_id} ì»¬ë ‰ì…˜ {collection_name}ì—ì„œ {len(points)}ê°œ í¬ì¸íŠ¸ ì¡°íšŒ")
                
                # í¬ì¸íŠ¸ë¥¼ ìˆœì„œ ì •ë³´ë¡œ ì •ë ¬
                sorted_points = self._sort_points_by_order(points)
                logger.info(f"ğŸ“‹ {len(sorted_points)}ê°œ í¬ì¸íŠ¸ ìˆœì„œ ì •ë ¬ ì™„ë£Œ")
                
                # í¬ì¸íŠ¸ë³„ë¡œ book_id ê·¸ë£¹í™”
                self._process_user_collection_points(sorted_points, user_books)
            
            except Exception as e:
                logger.error(f"ì»¬ë ‰ì…˜ {collection_name} ì¡°íšŒ ì‹¤íŒ¨: {e}")
            
            # ê²°ê³¼ í˜•ì‹ ë³€í™˜
            books_list = self._format_user_books_result(user_books)
            
            return {
                "user_id": user_id,
                "books": books_list,
                "total_books": len(books_list)
            }
            
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì {user_id} ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise VectorStoreError(f"ë¬¸ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    def _sort_points_by_order(self, points: List) -> List:
        """
        í¬ì¸íŠ¸ë¥¼ ìˆœì„œ ì •ë³´ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
        
        Args:
            points: Qdrantì—ì„œ ì¡°íšŒí•œ í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List: ìˆœì„œê°€ ì •ë ¬ëœ í¬ì¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        try:
            def get_sort_key(point):
                """í¬ì¸íŠ¸ì˜ ì •ë ¬ í‚¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
                if not point.payload or "metadata" not in point.payload:
                    return (0, 0, 0, 0, 0)  # ê¸°ë³¸ê°’
                
                metadata = point.payload["metadata"]
                book_id = metadata.get("book_id", 0)
                page_order = metadata.get("page_order", 0)
                chunk_order = metadata.get("chunk_order", 0)
                document_order = metadata.get("document_order", 0)
                upload_timestamp = metadata.get("upload_timestamp", 0)  # ì—…ë¡œë“œ ì‹œê°„ ì¶”ê°€
                
                # book_idë¥¼ ë¬¸ìì—´ë¡œ í†µì¼í•˜ì—¬ ë¹„êµ
                book_id_str = str(book_id) if book_id is not None else "0"
                
                # upload_timestampë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                try:
                    upload_timestamp = int(upload_timestamp) if upload_timestamp is not None else 0
                except (ValueError, TypeError):
                    upload_timestamp = 0
                
                # ìˆ«ìì™€ ë¬¸ìì—´ì„ êµ¬ë¶„í•˜ì—¬ ì •ë ¬
                try:
                    # ìˆ«ìì¸ ê²½ìš° ìˆ«ìë¡œ ì •ë ¬
                    book_id_num = int(book_id_str)
                    book_id_key = (0, book_id_num)  # ìˆ«ìëŠ” (0, ìˆ«ì)ë¡œ ì •ë ¬
                except (ValueError, TypeError):
                    # ë¬¸ìì—´ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ì •ë ¬
                    book_id_key = (1, book_id_str)  # ë¬¸ìì—´ì€ (1, ë¬¸ìì—´)ë¡œ ì •ë ¬
                
                return (book_id_key, upload_timestamp, page_order, chunk_order, document_order)
            
            # ìˆœì„œ ì •ë³´ë¡œ ì •ë ¬
            sorted_points = sorted(points, key=get_sort_key)
            return sorted_points
            
        except Exception as e:
            logger.warning(f"í¬ì¸íŠ¸ ì •ë ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ì›ë³¸ ìˆœì„œ ì‚¬ìš©: {e}")
            return points

    def _process_user_collection_points(self, points: List, user_books: Dict[str, Any]) -> None:
        """ì‚¬ìš©ì ì»¬ë ‰ì…˜ì˜ í¬ì¸íŠ¸ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        logger.info(f"ğŸ“‹ ì´ {len(points)}ê°œ í¬ì¸íŠ¸ ì²˜ë¦¬ ì‹œì‘")
        
        for i, point in enumerate(points):
            if not point.payload:
                continue
            
            # book_id ì¶”ì¶œ (ë©”íƒ€ë°ì´í„°ì—ì„œ)
            book_id = self._extract_book_id_from_payload(point.payload)
            
            # book_id ì •ë³´ ì¶”ì¶œ
            book_info = self._extract_page_info_from_payload(point.payload)
            
            if book_info:
                if book_id not in user_books:
                    user_books[book_id] = {"books": []}
                
                self._add_book_to_user_books(book_info, book_id, user_books)
        
        logger.info(f"âœ… í¬ì¸íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {len(user_books)}ê°œ book_id ê·¸ë£¹í™”ë¨")
    
    def _extract_book_id_from_payload(self, payload: Dict[str, Any]) -> str:
        """í˜ì´ë¡œë“œì—ì„œ book_idë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if "metadata" in payload and "book_id" in payload["metadata"]:
            book_id = payload["metadata"]["book_id"]
            return str(book_id) if book_id is not None else "default"
        return "default"
    
    def _add_book_to_user_books(self, book_info: Any, book_id: str, user_books: Dict[str, Any]) -> None:
        """book_id ì •ë³´ë¥¼ ì‚¬ìš©ì ì±…ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        if isinstance(book_info, list):
            for book in book_info:
                if isinstance(book, dict):
                    if "book_id" not in book:
                        book["book_id"] = book_id
                    user_books[book_id]["books"].append(book)
        elif isinstance(book_info, dict):
            if "book_id" not in book_info:
                book_info["book_id"] = book_id
            user_books[book_id]["books"].append(book_info)
    
    def _format_user_books_result(self, user_books: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ì ì±… ì •ë³´ë¥¼ ê²°ê³¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        books_list = []
        
        # book_idë³„ë¡œ ìˆœì°¨ ì²˜ë¦¬ (ìˆœì„œ ë³´ì¥)
        def sort_book_id_key(book_id):
            """book_idë¥¼ ì •ë ¬ ê°€ëŠ¥í•œ í‚¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
            try:
                # ìˆ«ìì¸ ê²½ìš° ìˆ«ìë¡œ ì •ë ¬
                return (0, int(book_id))
            except (ValueError, TypeError):
                # ë¬¸ìì—´ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ì •ë ¬
                return (1, str(book_id))
        
        for book_id in sorted(user_books.keys(), key=sort_book_id_key):
            book_data = user_books[book_id]
            # book_idë³„ë¡œ ëª¨ë“  ì²­í¬ ì •ë³´ ìˆ˜ì§‘
            all_chunks = []
            
            # ìˆœì„œ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì •ë ¬
            sorted_books = sorted(book_data["books"], 
                                key=lambda x: (
                                    x.get("page_keys", [0])[0] if x.get("page_keys") else 0,
                                    x.get("chunk_order", 0)
                                ))
            
            # ëª¨ë“  ì±… ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê° ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì €ì¥
            for book in sorted_books:
                page_keys = book.get("page_keys", [])
                content = book.get("content", "")
                
                # page_keysê°€ ë¹„ì–´ìˆê±°ë‚˜ contentê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                if not page_keys:
                    page_keys = [1]
                
                if not content:
                    content = "ë¬¸ì„œ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                # ê° page_keyì— ëŒ€í•´ ê°œë³„ ì²­í¬ë¡œ ì €ì¥
                for page_key in page_keys:
                    chunk_info = {
                        "pageKey": page_key,
                        "text": content,
                        "upload_timestamp": book.get("upload_timestamp", 0)
                    }
                    all_chunks.append(chunk_info)
            
            # ì²­í¬ë“¤ì„ pageKey ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì´ì¤‘ ë³´ì¥)
            all_chunks.sort(key=lambda x: x["pageKey"])
            
            books_list.append({
                "bookKey": str(book_id),
                "chunks": all_chunks
            })
        
        return books_list
    
    def _extract_page_info_from_payload(self, payload: Dict[str, Any]) -> Optional[List[Dict[str, Any]]]:
        """í˜ì´ë¡œë“œì—ì„œ book_id ê¸°ì¤€ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        if "page_content" not in payload:
            return None
        
        page_content = payload["page_content"]
        
        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = payload.get("metadata", {})
        book_id = metadata.get("book_id", "default")
        
        # page_keys ì²˜ë¦¬ - ì—¬ëŸ¬ í˜•íƒœ ì§€ì›
        page_keys = metadata.get("page_keys", [])
        if not page_keys:
            # page_keysê°€ ì—†ìœ¼ë©´ page_key(ë‹¨ìˆ˜) í™•ì¸
            page_key = metadata.get("page_key")
            if page_key is not None:
                page_keys = [page_key]
            else:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ 1 ì„¤ì •
                page_keys = [1]
        
        # ìˆœì„œ ì •ë³´ ì¶”ì¶œ
        chunk_order = metadata.get("chunk_order", 0)
        page_order = metadata.get("page_order", 0)
        document_order = metadata.get("document_order", 0)
        
        # upload_timestamp ì¶”ì¶œ
        upload_timestamp = metadata.get("upload_timestamp", 0)
        
        # book_id ê¸°ì¤€ ì •ë³´ êµ¬ì„± (ì²­í¬ ì •ë³´ í¬í•¨)
        book_info = {
            "book_id": book_id,
            "content": page_content,
            "page_keys": page_keys,
            "chunk_order": chunk_order,
            "page_order": page_order,
            "document_order": document_order,
            "upload_timestamp": upload_timestamp
        }
        return [book_info]
